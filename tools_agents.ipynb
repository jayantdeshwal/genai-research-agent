{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEARCH ENGINE WITH TOOLS AND AGENTS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv -- Research\n",
    "## Tools creation\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "\n",
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Correct Arxiv Setup ---\n",
    "api_wrapper_arxiv = ArxivAPIWrapper(\n",
    "    top_k_results=1, \n",
    "    doc_content_chars_max=250\n",
    ")\n",
    "# Pass the instantiated wrapper to the tool's REQUIRED 'api_wrapper' field\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv, name=\"arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wrapped_wiki,arxiv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom tool [RAG Tool]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs =  loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,embeddings)\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever, \"langsmith-search\", \"Search any information about Langsmith\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wrapped_wiki,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run all the tools with Agents and LLM Models\n",
    "## Tools,LLM-> Agent Executor\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified System Prompt\n",
    "system_prompt = \"\"\"You are a helpful assistant. You have access to tools to answer questions. Use them when necessary.\n",
    "\n",
    "When using the wikipedia tool, provide the input as a dictionary with a 'query' key. For example: {'query': 'Capital of France'}.You have access to the following tools:\n",
    "\n",
    "- wikipedia: Use this tool to find general information and answer questions about various topics.\n",
    "- arxiv: Use this tool to find research papers and information from scientific publications.\n",
    "- langsmith-search: Use this tool to find information about Langsmith.\n",
    "\n",
    "When answering questions, use the tools if needed to gather information. If you don't know the answer, say that you don't know.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def get_system_message_from_prompt(prompt):\n",
    "    \"\"\"\n",
    "    Returns a string system message if found, otherwise None.\n",
    "    Handles tuple shorthand, message objects, and PromptTemplate wrappers.\n",
    "    \"\"\"\n",
    "    for msg in prompt.messages:\n",
    "        # tuple/list shorthand: (\"system\", \"text\")\n",
    "        if isinstance(msg, (list, tuple)) and len(msg) >= 2:\n",
    "            if msg[0] == \"system\":\n",
    "                return msg[1]\n",
    "\n",
    "        # Real message objects (SystemMessage, HumanMessage, AIMessage)\n",
    "        # these usually expose .content and sometimes .role\n",
    "        if hasattr(msg, \"content\"):\n",
    "            role = getattr(msg, \"role\", None) or msg.__class__.__name__\n",
    "            # class name might be \"SystemMessage\"\n",
    "            if role == \"SystemMessage\" or (isinstance(role, str) and role.lower() == \"system\"):\n",
    "                return msg.content\n",
    "\n",
    "        # Prompt-template objects like SystemMessagePromptTemplate -> .prompt.template\n",
    "        tpl = getattr(getattr(msg, \"prompt\", None), \"template\", None)\n",
    "        if tpl:\n",
    "            # prefer explicit SystemMessagePromptTemplate class name or role attr\n",
    "            if msg.__class__.__name__ == \"SystemMessagePromptTemplate\" or getattr(msg, \"role\", None) == \"system\":\n",
    "                return tpl\n",
    "\n",
    "    return None\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "query = \"tell me about langsmith.\"\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
